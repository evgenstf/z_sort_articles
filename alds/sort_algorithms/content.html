<div class="article">
  <div class="article_header">Сортировки</div>

  <div class="article_subheader"><tr>
    <table width=100% style="border-collapse:collapse"><tr>
      <td style="width:100%">
        <div class="article_parent">
          <a style="color:#283593" href=/alds>Алгоритмы и структуры данных</a>
        </div>
      </td>
      <td style="padding:0px">
        <img src="{% static "svg/clock.svg" %}" width=16px height=16px style="margin-right:10px"/>
      </td>
      <td nowrap="nowrap">
        <div class="article_reading_time">
          20 min
        </div>
      </td>
    </tr></table>
  </div>

  <div class="article_body">
    <p>Все сортировки можно классифицировать по их свойствам:</p>
<h2>Устойчивость</h2>
<p><em>Stable-sort</em> или <em>устойчивая сортировка</em> - сортировка, которая гарантированно не поменяет местами одинаковые ключи. Если два ключа обладали одинаковыми значениями, то они останутся в том же порядке.</p>
<h3>Примеры устойчивых сортировок:</h3>
<ul>
<li>Сортировка слиянием (Merge-sort)</li>
<li>Сортировка пузырьком</li>
<li>Сортировка вставкой</li>
</ul><h2>Локальность</h2>
<p><em>Inplace-sort</em> или <em>локальная сортировка</em> -  сортировка, которая использует меньше, чем $O(log^kn)$ памяти, включая рекурсивные вызовы, где $n$ - количество элементов в сортируемом массиве, а $k$ - какая-то константа.</p>
<h3>Примеры локальных сортировок:</h3>
<ul>
<li>Быстрая сортировка (Quick-sort или Qsort)</li>
<li>Сортировка пузырьком</li>
<li>Сортировка выбором</li>
<li>Сортировка вставкой</li>
</ul>
<h2>Почему сортировка сравнением не может работать быстрее, чем  за $\Omega(n\log n)$</h2><h3>Доказательство для детерминированного алгоритма</h3>
<p><em>Можем ограничиться доказательством для массива со всеми различными элементами, так как используем оценку</em>$\Omega$.</p><p>Распишем определение $\Omega(n\log n)$:
$$\exists c &gt; 0:\forall  n&gt; N\; \exists input:\; |input|=n\;\; t(input) \geqslant c\cdot n\log{n}$$
* $c$ - некоторая константа
* $n$ - размер входных данных
* $input$ - входные данные
* $t(input)$ - время работы алгоритма на входных данных $input$</p><p>Представим ход работы алгоритма, как бинарное дерево, которое разветвляется, когда мы сравниваем два элемента (алгоритм полностью детерминирован, кроме моментов сравнения):
    * Пусть вершина дерева соответствует операции $a_i &lt; a_j$, где $a_i$, $a_j$ - элементы массива, который мы хотим отсортировать
    * Если условие выполнено ($a_i &lt; a_j$), то переходим в левого ребенка этой вершины.
    * Если условие не выполнено ($a_i \geqslant a_j$), то переходим в правого ребенка этой вершины.
<img alt="Дерево сравнений" src="{% static 'articles/alds/sort_algorithms/diagram_0.svg' %}" /></p><p>Если для разных перестановок элементов массива алгоритм совершит одни и те же действия, то результат будет различаться, чего не может быть $\Rightarrow$ для любых двух перестановок алгоритмы будут различны $\Rightarrow$ в таком дереве хотя бы $n!$ листьев ($n!$ - количество различных перестановок).
В каждом листе бинарного дерева находится какая-то из $n!$ перестановок изначального массива, которая показывает, в каком порядке стоят элементы после сортировки, относительно того как они стояли изначально $\Rightarrow$ существует лист, глубина которого $\geqslant\log n! \geqslant c \cdot n \log n$, так как $n! \geqslant \frac{n}{2}^{\frac{n}{2}}$.</p><h3>Доказательство для недетерминированного алгоритма</h3>
<p>Распишем определение $\Omega(n\log n)$:
$$\exists c &gt; 0:\forall  n&gt; N\; \exists input:\; |input|=n\;\; E(t(input)) \geqslant c\cdot n\log{n}$$
* $c$ - некоторая константа
* $n$ - размер входных данных
* $input$ - входные данные
* $E(t(input))$ - математическое ожидание времени работы алгоритма на входных данных $input$, где математическое ожидание - это среднее по всем наборам случайных значений $random$.</p><p>Введем обозначения:
* $\max\limits_{x} (f(x))$ - максимальное значение функции $f(x)$ по всем $x$
* $avg_x(f(x))$ - среднее значение функции $f(x)$ по всем $x$</p><p>И запишем определение в другом виде:
$$\max\limits_{input} (avg_{random} t(input, random)) \geqslant c\cdot n\log{n}$$
Так как $\max\limits_{x} (f(x)) \geqslant avg_x(f(x))$, то верно:
$$\max\limits_{input} (avg_{random} t(input, random)) \geqslant avg_{input} (avg_{random} t(input, random))$$
Можем поменять местами $avg_{random}$ и $avg_{input}$, так как от этого формула не изменится:
$$\max\limits_{input} (avg_{random} t(input, random)) \geqslant avg_{random} (avg_{input} t(input, random))$$
Теперь random зафиксирован, то есть определена последовательность случайных значений $\Rightarrow$ алгоритм становится детерминированным.
Вспомним бинарное дерево, которое мы строили в доказательстве для детерменированных алгоритмов, теперь нужно доказать, что средняя глубина по всем $n!$ листьям ($p$ - лист или перестановка):
$$avg_p d \geqslant c\cdot n\log{n}$$
Рассмотрим глубину $d = \log n! - 1$. На такой глубине листьев может быть не больше, чем $2^{\log n! - 1} \leq \frac{n!}{2} \Rightarrow$ на глубине меньше, чем $\log n! - 1$ может находится максимум половина листье $\Rightarrow$ вторая половина листьев находится хотя бы на глубине $\log n!$ $\Rightarrow$ средняя глубина по всем листьям хотя бы $\log \frac{n}{2}$ $\Rightarrow$ если в дереве $n!$ листьев, то средняя глубина хотя бы $c\cdot n\log{n}$:
$$avg_{input} t(input, random) \geqslant c\cdot n\log{n}$$
Тогда определение $\Omega(n\log n)$ доказано, так как верно:
$$avg_{random} (avg_{input} t(input, random)) \geqslant c\cdot n\log{n}$$</p><h2>Сортировки, которые обращаются к значению своего элемента</h2>
<h3>Сортировка подсчетом (Count sort)</h3>
<p>Сортировка, которая для каждого элемента вычисляет, сколько раз он встречается
* $a_1, a_2, ..., a_n$ - последовательность целых чисел, которую нужно отсортировать
* $[0, U-1]$ - диапазон, в котором лежат все $a_i$, причем $U = 2^k$</p><p>Так как $U = 2^k$, то можно считать, что мы сортируем набор битовых строк одинаковой длины. При этом длина машинного слова позволяет нам этими числами оперировать: в word-RAM параметр длины слова $w \geqslant k$.
* $a_i$ - битовая строка длины $k$.</p><h4><em>Алгоритм:</em></h4>
<ul>
<li>В массив $u$ длины $U$  в ячейку с индексом $j$ записывается количетсво таких $i \leq n$, что $a_i = j$, то есть сколько раз число $j$ встретилось в массиве $a$. (<em>Оценка времени:</em> $O(n)$ - <em>один проход по массиву</em> $a$)</li>
<li>Восстановление отсортированной последовательности: еще раз пройдем по массиву $u$ и каждый индекс $j$ выведем $a[j]$ раз. (<em>Оценка времени:</em> $O(U)$ - <em>один проход по массиву</em> $u$)</li>
</ul><p><strong><em>Оценка времени:</em></strong> $O(n + U)$</p><h4>Задача:</h4>
<p>Дан массив пар ${(a_1, b_1), (a_2, b_2), ... , (a_n, b_n)}$, $a_i, b_i \in [0, U - 1]$. С помощью сортировки подсчетом нужно упорядочить эти пары так, что пары сначала сравниваются по первому элементу, а потом по второму.
<em>Решение:</em> Отсортируем сначала по второму элементу в паре, а потом по первому, при этом будем использовать устойчивую сортировку. <em>(Аналогично задача решается и для кортежей произвольной длины).</em></p><h3>Поразрядная сортировка (Radix sort)</h3>
<p>Рассмотренная выше сортировка подсчетом имеет существенный недостаток: под каждое возможное значение числа $a_i$ нам нужно выделить ячейку в массиве $u$. Поразрядная сортировка лишена этого недостатка.</p>
<h4><em>Алгоритм:</em></h4>
<p><em>Дан массив двоичных строк: 011, 101, 001, 010, 110. Нужно его отсортировать.</em>
1. Создаем пустые массивы, количество которых равно числу возможных значений одного разряда $a_i$.
<em>В нашем случае  $a_i$ - двоичное слово, поэтому возможны всего два значения одного разряда - 0 или 1</em>
2. Распределяем исходные числа по этим спискам в зависимости от величины младшего разряда (по возрастанию). То есть помещаем число в $i$-ый массив , если его младший разряд равен $i$.
В нашем случае массивы будут выглядеть следующим образом:)</p><pre><code>| i = 0 | i = 1 |
|--|--|
| 010 | 011 |
| 110 | 101 |
|  -  | 001 |
</code></pre>
<ol>
<li>Идем по массивам в порядке возрастания $i$ и записываем числа в той последовательности, в которой они встречаются.
<em>Получим следующую последовательность: 010, 110, 011, 101, 001</em></li>
<li>Повторяем пункты 2 и 3 для всех более старших разрядов поочередно.
<em>В нашем случае придется проделать эти операции еще 2 раза, так как всего разрядов - 3. Отсортированная последовательсность будет выглядеть так: 001, 010, 011, 101, 110</em></li>
</ol><p><strong><em>Оценка времени:</em></strong> $O(n + U')$, где $U'$ - количество возможных значений одного разряда.</p>
<h4>Оптимизация:</h4>
<ul>
<li>Для случая с битовыми строками оценка времени работы поразрядной сортировки будет $O(n \log U)$ - заметим, что такая оценка невыгодн для нас, всегда можно отсортировать быстрее. за $O(n \log n)$</li>
<li>Тогда выберем такое $k'$, что $2^{k'} \approx n$, и разобьем биты строки на блоки длины $k'$. Получается, что теперь мы сортируем кортежи длиной $\frac{k}{k'} = \frac{\log U}{\log n}$ <em>(подобная задача рассмотрена выше)</em>.</li>
<li>Новая оценка времени будет: $\frac{\log U}{\log n} \cdot \theta(n + U') = \frac{\log U}{\log n} \cdot \theta(n + n) = O(n\frac{\log U}{\log n})$, а это уже лучше, чем $O(n \log n)$ при $U &lt; n^2$.
<strong><em>Итоговая оценка времени:</em></strong> $O(n\frac{\log U}{\log n})$</li>
</ul><h3>Корзинная или карманная сортировка (Bucket sort)</h3>
<h4><em>Алгоритм:</em></h4>
<ul>
<li>Выберем $k'$ и поделим отрезок $[0, U - 1]$  на $2^{k'}$ "корзин" или отрезков.</li>
<li>Идем по данной последовательсности $a_1, a_2, ..., a_n$ и для каждого $a_i$ определяем, в какую корзину он попадет, и по этому признаку разбиваем последовательность на $2^{k'}$ групп или "корзин".</li>
<li>Для каждой корзины сортируем попавшие в нее числа и объединяем результат. Сортировать можно, как корзинной сортировкой, так и любой другой.</li>
</ul><h4><em>Оценка времени:</em></h4>
<p>В самом худшем случае алгоритм будет работать за $O(n \log U)$, но худший случай встречается очень редко или даже почти никогда. Чтобы оценить среднее время работы $t(n)$, решим следующую задачу:</p><ul>
<li>Дана последовательность вещественных чисел $x_1, x_2, ... , x_n$, случайно сгенерированных на отрезке $[0, 1]$. Для сортировки будем использовать следующий алгоритм:</li>
<li>На первом шаге применим корзинную сортировку. Разобьем отрезок $[0, 1]$ на $n$ корзин. Распределим $x_i$ по корзинам.</li>
<li>На втором шаге внутри каждой корзины отсортируем пузырьком</li>
</ul><p>Найдем математическое ожидание времени работы данного алгоритма. Пусть $s_i$ - количество элементов, которые попали в $i$-ую корзину, a $a, b$ - некоторые константы:
     $$Et(n) = an + E \sum_{i = 1}^n b\cdot s_i^2 = an + E \sum_{i = 1}^n b\cdot s_is_i$$
     Введем обозначение $A_{ij}$, которое отвечает за событие: элемент $i$ в корзине $j$, и $I_{A_{ij}}$ - индикатор события $A_{ij}$, который равен 1, если событие произошло и 0 иначе. тогда:
     $$Et(n) = an + E \sum_{i = 1}^n b(\sum_{j = 1}^n I_{A_{ij}}) (\sum_{j = 1}^n I_{A_{ij}}) = an + E\sum_{j = 1}^n\sum_{k = 1}^n\sum_{i = 1}^nb(A_{ij} \cap A_{ik})$$
     Сумма $\sum_{i = 1}^n(A_{ij} \cap A_{ik})$ принимает значения либо 0, либо 1, поэтому можем переписать, используя событие $B_{jk}$ - элементы $j$ и $k$ в одной корзине:
     $$Et(n) = an + E\sum_{j = 1}^n\sum_{k = 1}^nb\cdot I_{B_{jk}}$$
     Разложим матожидание на сумму двух слагаемых, когда элементы $j$ и $k$ совпадают и не совпадают:
     $$Et(n) = an + E\sum_{j = 1}^nb\cdot I_{B_{jj}} + E\sum_{j &lt; k}^n2b\cdot I_{B_{jk}}$$
    Тогда $Et(n)$ можно оценить следующим образом:
    $$Et(n)\leqslant an + bn + bn^2 \cdot \frac{1}{n} = an + bn + bn = n (a + 2b)$$
    Так как $a, b$ - константы то <strong>время работы линейно</strong>.</p>
  </div>

  <div id="footnote_container"></div>

  <div class="article_tail">
    <div class="article_authors">Belloid</div>
    <div class="article_date">9 Декабря 2020</div>
  </div>
</div>
