<div class="article">
  <div class="article_header">Оценка времени работы алгоритмов</div>

  <div class="article_subheader"><tr>
    <table width=100% style="border-collapse:collapse"><tr>
      <td style="width:100%">
        <div class="article_parent">
          <a style="color:#283593" href=/alds>Алгоритмы и структуры данных</a>
        </div>
      </td>
      <td style="padding:0px">
        <img src="{% static "svg/clock.svg" %}" width=16px height=16px style="margin-right:10px"/>
      </td>
      <td nowrap="nowrap">
        <div class="article_reading_time">
          12 минут
        </div>
      </td>
    </tr></table>
  </div>

  <div class="article_body">
    <p>Вероятностное пространство. Случайная величина, ее распределение, матожидание, мода и медиана.</p><p><strong>Примечание</strong>: <em>Большинство приведённых ниже определений верны только для случая конечного множества элементарных исходов, хотя и сохраняют свой смысл при обобщении</em></p>
<h1>Вероятностное пространство</h1>
<p><em>Вероятностное пространство</em> -- это тройка $(\Omega, 2^{\Omega}, P)$, где </p>
<ul>
<li>$\Omega$ -- множество <span class="footnote_link" id="1" onclick='showFootnote("1")' footnote-title="Подробнее?" footnote-text="<p>Исходы случайного эксперимента. Например, подбрасывания монеты. Обозначаются как $\omega\in\Omega.$</p>">элементарных исходов</span class="footnote_link" id="1" onclick='showFootnote("1")' footnote-title="Подробнее?" footnote-text="<p>Исходы случайного эксперимента. Например, подбрасывания монеты. Обозначаются как $\omega\in\Omega.$</p>"> </li>
<li>$2^{\Omega}$ -- <span class="footnote_link" id="2" onclick='showFootnote("2")' footnote-title="А это что?" footnote-text="<p>Подмножество множества случайных экспериментов $\Omega$</p>">случайные события</span class="footnote_link" id="2" onclick='showFootnote("2")' footnote-title="А это что?" footnote-text="<p>Подмножество множества случайных экспериментов $\Omega$</p>"> </li>
<li>$P$ -- определенная на всех элементарных исходах функция вероятности</li>
</ul>
<h1>Вероятность</h1>
<p><em>Вероятность</em> -- функция $P(\omega)$, которая каждому элементарному исходу сопоставляет число от 0 до 1.</p>
<h2>Вероятность события</h2>
<p><em>Вероятность события</em> -- сумма вероятностей составляющих его элементарных исходов: 
$$P(A) = \sum_{\omega\in A}P(\omega)$$</p>
<ul>
<li>Если $P(A) = 0$, то событие $A$ <em>невозможное</em>. </li>
<li>Если $P(A) = 1$, то событие $A$ <em>достоверное</em>.</li>
</ul>
<h2>Независимость событий</h2>
<p>События $A$ и $B$ называют <em>независимыми</em>, если вероятность наступления события $B$ не меняется при наступлении события $A$, и наоборот. То есть при $P(A) &gt; 0, P(B) &gt; 0$ выполнено: 
$$P(A\cap B) = P(A)\cdot P(B)$$</p>
<ul>
<li>Если при $P(A) &gt; 0, P(B) &gt; 0$ выполнено $P(A\cap B) = 0$, то события $A$ и $B$ называют <em>несовместными</em>.</li>
</ul>
<p>События $A_1, A_2, . . . , A_n$ называются <em>попарно независимыми</em>, если любые два из них являются независимыми.</p>
<p>События $A_1, A_2, . . . , A_n$ называются <em>независимыми в совокупности</em>, если для любого подмножества этих событий $A_{i_1} , A{i_2} , . . . , A{i_k}$ выполнено: 
$$P(A_{i_1} \cap A{i_2} \cap . . . \cap A{i_k}) = P(A_{i_1}) \cdot P(A_{i_2}) \cdot ... \cdot P(A_{i_n})$$</p>
<h2>Условная вероятность</h2>
<p><em>Условная вероятность</em> -- вероятность наступления события $A$ при условии, что событие $B$ произошло, обозначается как $P(A|B)$. При $P(B) &gt; 0$ выполнено: 
$$P(A|B) = \frac{P(A\cap B)}{P(B)}$$</p>
<h2>Полная группа событий</h2>
<p>События $A_1, A_2, . . . , A_n$ называют <em>полной группой событий</em>, если любой элементарный исход принадлежит <strong>ровно одному</strong> из них. (То есть в результате проведения случайного эксперимента обязательно произойдет одно и только одно из событий $A_1, A_2, . . . , A_n$) 
* Если события $A_1, A_2, . . . , A_n$ образуют полную группу, то для любого события $B$ выполнено : 
$$P(B) = \sum_{i =1}^n P(B|A_i)\cdot P(A_i)$$</p>
<h1>Случайная величина</h1>
<p><em>Случайная величина</em> -- отображение $\psi : \Omega \rightarrow R$ из множества исходов в множество вещественных значений.</p>
<h2>Пример с кубиком</h2>
<p>При броске игрального кубика множество элементарных исходов будут составлять выпадающие грани. Случайной величиной в таком случае может быть количество точек на выпавшей грани.</p>
<p><img alt="Playing dice" src="https://habrastorage.org/webt/vh/uk/lq/vhuklqliqxtkaki6kt0ybph4q-e.png" /> 
Можно заметить, что тогда для случайной величины можно посчитать ее вероятность, исходя из вероятностей элементарных исходов. В данном случае, например, вероятность получить при броске 4 равна $P(\psi = 4) = \frac{1}{6}$.</p>
<h2>Распределение случайной величины</h2>
<p>Чаще всего при работе со случайной величиной хочется понимать ее поведение в совокупности на всем множестве значений. Для этого хорошо подходит ее <em>распределение</em>. Для дискретного случая, интересующего нас, это просто сама функция $P(\psi = x)$, определяющая вероятность принятия случайной величиной значения $x$.</p>
<p>Например, вот так в общих чертах выглядит распределение роста мужчин и женщин: 
<img alt="" src="https://habrastorage.org/webt/3j/vo/3m/3jvo3m8ld-ldckzpif6olkkfqf8.png" /></p>
<h2>Математическое ожидание</h2>
<p><em>Математическое ожидание</em> -- средневзвешанное значение случайной величины. Можно выразить двумя способами:</p>
<ul>
<li>$E(\psi) = \sum_{\omega \in \Omega} \psi(\omega) \cdot P(\omega)$ -- сумма произведений случайных значений всех возможных элементарных исходов на их вероятности </li>
<li>$E(\psi) = \sum_{x \in V(\psi)} x \cdot P(\psi = x)$ -- сумма произведений всех возможных <span class="footnote_link" id="0" onclick='showFootnote("0")' footnote-title="В чем отличие от первого способа?" footnote-text="<p>Мы объединили элементарные исходы по случайным значениям</p>">случайных значений</span class="footnote_link" id="0" onclick='showFootnote("0")' footnote-title="В чем отличие от первого способа?" footnote-text="<p>Мы объединили элементарные исходы по случайным значениям</p>"> на их вероятности</li>
</ul>
<h2>Мода и медиана</h2>
<p><em>Мода случайной величины</em> -- значение, которое случайная величина примет с наибольшей вероятностью.</p>
<p><em>Медиана случайной величины</em> -- такое значение $x$, что $P(\psi &lt; x) \leq \frac{1}{2}$ и $P(\psi &gt; x) \geq \frac{1}{2}$. Другими словами,  половина исходов дает большее значение и половина меньшее.</p>
<h2>Независимость случайной величины</h2>
<p>Две случайные величины $\xi, \psi$ независимы, если  $\forall x, y : P(\xi = x, \psi = y) = P(\xi = x) \cdot P(\psi = y)$.</p>
<h2>Свойства математического ожидания</h2>
<ul>
<li>
<p><em>Линейность</em> -- математическое ожидание линейной комбинации двух случайных величин равно линейной комбинации их математических ожиданий: 
$$E(\alpha \psi + \beta \xi) = \alpha E(\psi) + \beta E(\xi)$$ <strong>Не требует независимости случайных величин</strong></p>
</li>
<li>
<p>Если случайные величины независимы, то математическое ожидание их произведения равно произведению математических ожиданий: 
$$E(\psi \cdot \xi)= E(\psi) \cdot E(\xi)$$ <strong>Требует независимости случайных величин</strong></p>
</li>
</ul>
<h1>Оценка времени работы</h1>
<ul>
<li>Для детерминированных алгоритмов под временем работы подразумевается время работы на худшем тесте.</li>
</ul>
<p><strong>TO BE CONTINUED</strong></p>
  </div>

  <div id="footnote_container"></div>

  <div class="article_tail">
    <div class="article_authors">evgenstf<br>Belloid</div>
    <div class="article_date">27 Ноября 2020</div>
  </div>
</div>
