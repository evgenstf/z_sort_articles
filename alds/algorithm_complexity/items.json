[{
  "type":"tldr",
  "content":"Вероятностное пространство. Случайная величина, ее распределение, матожидание, мода и медиана."
},
{"type":"markdown",
  "content":"# Вероятностное пространство\n \n*Вероятностное пространство* -- это тройка $(\\Omega, 2^{\\Omega}, P)$, где \n\n* $\\Omega$ -- множество <!элементарных исходов!>(Подробнее?){Исходы случайного эксперимента. Например, подбрасывания монеты} \n* $2^{\\Omega}$ -- <!случайные события!>(А это что?){Подмножество множества случайных экспериментов $\\Omega$} \n* $P$ -- определенная на всех элементарных исходах функция вероятности\n \n# Случайная величина \n*Случайная величина* -- отображение $\\psi : \\Omega \\rightarrow R$ из множества исходов в множество вещественных значений.\n \n## Пример с кубиком \nПри броске игрального кубика множество элементарных исходов будут составлять выпадающие грани. Случайной величиной в таком случае может быть количество точек на выпавшей грани.\n \n![Playing dice](https://habrastorage.org/webt/vh/uk/lq/vhuklqliqxtkaki6kt0ybph4q-e.png) \nМожно заметить, что тогда для случайной величины можно посчитать ее вероятность, исходя из вероятностей элементарных исходов. В данном случае, например, вероятность получить при броске 4 равна $P(\\psi = 4) = \\frac{1}{6}$.\n \n## Распределение случайной величины\n \nЧаще всего при работе со случайной величиной хочется понимать ее поведение в совокупности на всем множестве значений. Для этого хорошо подходит ее *распределение*. Для дискретного случая, интересующего нас, это просто сама функция $P(\\psi = x)$, определяющая вероятность принятия случайной величиной значения $x$.\n \nНапример, вот так в общих чертах выглядит распределение роста мужчин и женщин: \n![](https://habrastorage.org/webt/3j/vo/3m/3jvo3m8ld-ldckzpif6olkkfqf8.png)\n \n## Математическое ожидание\n \n*Математическое ожидание* -- средневзвешанное значение случайной величины. Можно выразить двумя способами:\n \n* $E(\\psi) = \\sum_{\\omega \\in \\Omega} \\psi(\\omega) \\cdot P(\\omega)$ -- сумма произведений случайных значений всех возможных элементарных иÑходов на их вероятности \n* $E(\\psi) = \\sum_{x \\in V(\\psi)} x \\cdot P(\\psi = x)$ -- сумма произведений всех возможных <!случайных значений!>(В чем отличие от первого способа?){Мы объединили элементарные исходы по случайным значениям} на их вероятности\n \n## Мода и медиана\n \n*Мода случайной величины* -- значение, которое случайная величина примет с наибольшей вероятностью.\n \n*Медиана случайной величины* -- такое значение $x$, что $P(\\psi < x) \\leq \\frac{1}{2}$ и $P(\\psi > x) \\geq \\frac{1}{2}$. Другими словами,  половина исходов дает большее значение и половина меньшее.\n \n## Независимость случайной величины\n \nДве случайные величины $\\xi, \\psi$ независимы, если  $\\forall x, y : P(\\xi = x, \\psi = y) = P(\\xi = x) \\cdot P(\\psi = y)$.\n \n## Свойства математического ожидания\n \n* *Линейность* -- математическое ожидание линейной комбинации двух случайных величин равно линейной комбинации их математических ожиданий: \n$$E(\\alpha \\psi + \\beta \\xi) = \\alpha E(\\psi) + \\beta E(\\xi)$$ <p style='text-align: right;'>**Не требует независимости случайных величин**</p>\n \n* Если случайные величины независимы, то математическое ожидание их произведения равно произведению математических ожиданий: \n$$E(\\psi \\cdot \\xi)= E(\\psi) \\cdot E(\\xi)$$ <p style='text-align: right;'>**Требует независимости случайных величин**</p>\n \n# Оценка времени работы\n \n* Для детерминированных алгоритмов под временем работы подразумевается время работы на худшем тесте.\n \n**TO BE CONTINUED**" }]
